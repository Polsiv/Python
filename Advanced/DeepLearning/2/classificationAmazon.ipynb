{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "import os\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9a2b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/poorveshchaudhari/amazon-fashion-products?dataset_version_number=1&file_name=products.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.64M/2.64M [00:00<00:00, 5.71MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the file you'd like to load\n",
    "file_path = \"products.csv\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.dataset_load(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"poorveshchaudhari/amazon-fashion-products\",\n",
    "    file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9cc3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"image_url\", \"brand\"])\n",
    "df = df[[\"image_url\", \"brand\"]]\n",
    "\n",
    "# since there are brands with ONLY 1 record, group them into the misc class\n",
    "min_count = 10\n",
    "brand_counts = df[\"brand\"].value_counts()\n",
    "df[\"brand\"] = df[\"brand\"].apply(lambda x: x if brand_counts[x] >= min_count else \"misc\")\n",
    "\n",
    "# now cast the classes into integers.\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"brand\"] = label_encoder.fit_transform(df[\"brand\"])\n",
    "df[\"brand\"] = df[\"brand\"].astype(np.int32)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "train_df, val_df = train_test_split(train_df, test_size = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "389bd3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "IMG_DIR = \"images\"\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def fetch_images(path, label):\n",
    "    path = path.numpy().decode('utf-8')\n",
    "\n",
    "    try:\n",
    "        img = tf.keras.utils.load_img(path, target_size = IMG_SIZE)\n",
    "        img = tf.keras.utils.img_to_array(img) / 255.0 # since every pixel has values [0, 255], dividing by 255 normalizes them to [0, 1]\n",
    "    except Exception:\n",
    "        img = np.zeros((*IMG_SIZE, 3), dtype = np.float32)\n",
    "\n",
    "    return img.astype(np.float32), np.int32(label)\n",
    "\n",
    "def tf_fetch_image(url, label):\n",
    "    img, lbl = tf.py_function(fetch_images, [url, label], [tf.float32, tf.int32])\n",
    "    img.set_shape((*IMG_SIZE, 3))\n",
    "    lbl.set_shape(())\n",
    "\n",
    "    return img, lbl\n",
    "\n",
    "def make_datasets(sub_dataframe):\n",
    "    paths = [os.path.join(IMG_DIR, f\"{i}.jpg\") for i in sub_dataframe.index]\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, sub_dataframe[\"brand\"].values))\n",
    "    ds = ds.map(tf_fetch_image, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    ds = ds.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds, val_ds, test_ds = make_datasets(train_df), make_datasets(val_df), make_datasets(test_df)\n",
    "\n",
    "\n",
    "print(train_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a6d31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 128, 128, 3) [113 144  62 149 173  81 124 184  30  46 113 184  48 113  92 140 182  40\n",
      " 184 184   0  48  97 184  11 184  15 184  67 143  12  42]\n",
      "Image shape: (128, 128, 3)\n",
      "Pixel values (first image):\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  ...\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "# here we can visualize the data (optional)\n",
    "\n",
    "\"\"\"\n",
    "the first for loop displays:\n",
    "\n",
    "(32, 224, 224, 3) [3.3, ...., 1.5]\n",
    "\n",
    "Here we have:\n",
    "- a batch of 32 images\n",
    "- 224x224 each (and their 3 respetive channels)\n",
    "- [ints] the array of brands for each image\n",
    "\"\"\"\n",
    "\n",
    "for img, lbl in train_ds.take(1):\n",
    "    print(img.shape, lbl.numpy())\n",
    "\n",
    "\"\"\"\n",
    "second for loop shows the values for each pixel\n",
    "\n",
    "For each image we have:\n",
    "- first axis: rows (height = 224)\n",
    "- second axis: columns (width = 224)\n",
    "- third axis: channels (RGB = 3)\n",
    "\"\"\"\n",
    "for imgs, labels in train_ds.take(1):\n",
    "    print(\"Image shape:\", imgs[1].shape)\n",
    "    print(\"Pixel values (first image):\")\n",
    "    print(imgs[1].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a10b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(hp, num_classes):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # input layer\n",
    "    model.add(tf.keras.layers.Input(shape = (128, 128, 3)))\n",
    "\n",
    "    # convolutional layers\n",
    "    for i in range(hp.Int(\"num_conv_layers\", 1, 3)):\n",
    "        model.add(tf.keras.layers.Conv2D(\n",
    "            filters = hp.Int(f\"filters_{i}\", min_value = 32, max_value = 128, step = 32),\n",
    "            kernel_size = hp.Choice(\"kernel_size\", values = [3, 5]),\n",
    "            activation = \"relu\",\n",
    "            padding = \"same\"\n",
    "        ))\n",
    "        model.add(tf.keras.layers.MaxPooling2D(pool_size = 2))\n",
    "\n",
    "    model.add(tf.keras.layers.av())\n",
    "\n",
    "    # dense layers\n",
    "    for j in range(hp.Int(\"num_dense_layers\", 0, 2)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units = hp.Int(f\"units_dense_{j}\", min_value = 64, max_value = 256, step = 64),\n",
    "            activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "        ))\n",
    "\n",
    "    # output layer for classification\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation = \"softmax\"))\n",
    "\n",
    "    # hyperparameter: learning rate\n",
    "    hp_lr = hp.Choice(\"learning_rate\", values = [1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    # compile for classification\n",
    "    model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = hp_lr),\n",
    "        loss = \"sparse_categorical_crossentropy\",\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f28d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cnn_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel = build_cnn_model,\n",
    "    objective = \"val_accuracy\",\n",
    "    max_trials = 10,\n",
    "    directory = \"my_dir\",\n",
    "    project_name = \"cnn_classification_tunning\",\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479f430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the best model\n",
    "best_model = tuner.get_best_models(num_models = 1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis = 0)\n",
    "y_pred_probs = best_model.predict(test_ds)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "loss, acc = best_model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
