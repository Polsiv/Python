# -*- coding: utf-8 -*-
"""clasificador_de_plantas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ulgkx_OdgEzZga2929CBgJ_fTOQxfnG
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.regularizers import l1, l2
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, roc_curve
from sklearn.preprocessing import label_binarize
import seaborn as sns
# import some data to play with
iris = datasets.load_iris() # https://archive.ics.uci.edu/ml/datasets/iris
X = iris.data # características
y = iris.target # etiquetas (0, 1, 2)

# Crear un DataFrame para facilitar la visualización
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = iris.target

# Mapeo de especies a nombres
df['species'] = df['species'].map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})




print("Las caracteristicas: \n", X)
print("Las estiquetas son : \n", y)
#Converting the dataset to pandas dataframe
iris = pd.DataFrame(
    data= np.c_[iris['data'], iris['target']],
    columns= iris['feature_names'] + ['target']
    )
print (iris)

y = pd.get_dummies(y).values
print("Datos one hot encoding \n :", y)

# Split the data into a training set and a test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Definir el modelo secuencial
# Crear el modelo con regularización L1 y L2
# Crear el modelo
model = tf.keras.Sequential()
#Define a model

# Capa de entrada y capa oculta (se ajusta a la cantidad de características de entrada)
model.add(tf.keras.layers.Dense(units=32, input_dim=X.shape[1], activation='tanh', kernel_regularizer=l2(0.01)))  # Capa oculta con 'tanh', # Regularización L1
model.add(tf.keras.layers.Dense(units=16, activation='tanh', kernel_regularizer=l2(0.01)))  # Capa oculta con 'tanh', # Regularización L2
# Capa de salida para 3 clases con 'softmax' para clasificación multiclase
model.add(tf.keras.layers.Dense(units=3, activation='softmax'))

#regularizacion por parada temprana
# Definir el callback de Early Stopping
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',  # Monitorea la métrica val_loss
                               patience=6,         # Paciencia de 3 épocas sin mejora
                               mode='min',         # Queremos minimizar val_loss
                               restore_best_weights=True)  # Restaura los mejores pesos
'''
monitor: Especifica qué métrica se quiere monitorizar (por ejemplo, val_loss, val_accuracy).
patience: Número de épocas que el modelo puede continuar entrenando sin mejorar antes de que se detenga.
mode: Puede ser 'min', 'max' o 'auto', dependiendo de si se está minimizando o maximizando la métrica. Por ejemplo, para val_loss se utiliza 'min' porque queremos minimizarla.
restore_best_weights: Si se establece como True, restaura los pesos del modelo a la mejor época antes de que comenzara a empeorar.
'''

#Compile and train the model
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
              #metrics=[tf.keras.metrics.Recall()]) #metricas: https://keras.io/api/metrics/

history = model.fit(X_train, y_train,
                    validation_split=0.3,
                    batch_size=15,
                    epochs=100,
                    #callbacks=[early_stopping],  # Aplicar Early Stopping
                    validation_freq=1) #https://keras.io/api/models/model_training_apis/
#history = model.fit(X_train, y_train, batch_size=5, epochs=100)

# list all data in history
print(history.history.keys())
epochs = range(1, len(history.history['accuracy']) + 1)
# summarize history for accuracy
plt.figure()
plt.plot(epochs,history.history['accuracy'])
plt.plot(epochs,history.history['val_accuracy']) # epochs[1::validation_freq]
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
#plt.legend(['train'], loc='upper left')
plt.legend(['train', 'test'], loc='upper left')
#plt.show()
# summarize history for loss
plt.figure()
plt.plot(epochs, history.history['loss'])
plt.plot(epochs, history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
#plt.legend(['train'], loc='upper left')
plt.legend(['train', 'test'], loc='upper left')
#plt.show()

# Evaluate the model with test data
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print('Test loss:', loss)
print('Test accuracy:', accuracy)

#Predict test data
y_pred = model.predict(X_test)
print("Salidas predichas", y_pred)
#Print actual and predicted value
actual = np.argmax(y_test,axis=1)
predicted = np.argmax(y_pred,axis=1)
print(f"Actual: {actual}")
print(f"Predicted: {predicted}")

#--------matrix confusion-----

# Compute confusion matrix
print("datos reales", y_test)
print("datos predichos", predicted)
#cm = confusion_matrix(y_test, y_pred)
cm = confusion_matrix(actual, predicted)

print(cm)

# Show confusion matrix in a separate window
plt.matshow(cm)
plt.title('Confusion matrix')
plt.colorbar()
plt.ylabel('True label')
plt.xlabel('Predicted label')

#------metricas------
n_classes = 3
y_true = actual
# Binarizar las etiquetas para ROC AUC
y_true_bin = label_binarize(y_true, classes=[0, 1, 2])
# Calcular Precision, Recall, F1-Score y Accuracy para el problema multiclase
precision_macro = precision_score(y_true, predicted, average='macro')
recall_macro = recall_score(y_true, predicted, average='macro')
f1_macro = f1_score(y_true, predicted, average='macro')
accuracy = accuracy_score(y_true, predicted)

# Calcular AUC (Area Under the Curve) para cada clase
auc = roc_auc_score(y_true_bin, y_pred, multi_class="ovr")

# Mostrar las métricas
print(f'Precisión (Macro): {precision_macro:.2f}')
print(f'Recall (Macro): {recall_macro:.2f}')
print(f'F1-Score (Macro): {f1_macro:.2f}')
print(f'Exactitud (Accuracy): {accuracy:.2f}')
print(f'AUC (OvR): {auc:.2f}')

# Calcular métricas clase por clase
for i in range(n_classes):
    print(f"\nMétricas para la clase {i}:")

    # Convertir la clase actual en un problema binario (One vs Rest)
    y_true_binary = (y_true == i).astype(int)  # 1 para la clase actual, 0 para el resto
    y_pred_binary = (predicted == i).astype(int)  # Predicciones convertidas a binario

    # Calcular precisión, recall, f1-score y accuracy para la clase actual
    precision = precision_score(y_true_binary, y_pred_binary)
    recall = recall_score(y_true_binary, y_pred_binary)
    f1 = f1_score(y_true_binary, y_pred_binary)
    accuracy = accuracy_score(y_true_binary, y_pred_binary)

    # Mostrar las métricas
    print(f'Precisión: {precision:.2f}')
    print(f'Recall: {recall:.2f}')
    print(f'F1-Score: {f1:.2f}')
    print(f'Exactitud (Accuracy): {accuracy:.2f}')
    print(f'AUC: {auc:.2f}')

# Calcular ROC curve para cada clase
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred[:, i])
    roc_auc[i] = roc_auc_score(y_true_bin[:, i], y_pred[:, i])

# Graficar las curvas ROC para cada clase
plt.figure()
colors = ['blue', 'green', 'red']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'Clase {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curvas ROC para Clasificación Multiclase')
plt.legend(loc="lower right")
plt.show()

