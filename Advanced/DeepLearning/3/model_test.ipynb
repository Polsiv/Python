{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ed7ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import Compose, LoadImage, ScaleIntensity, EnsureChannelFirst, Resize \n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from monai.transforms import Compose, EnsureChannelFirst, ScaleIntensity, Resize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fe1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.dataframe = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    \n",
    "    def _load_dicom_series(self, directory_path):\n",
    "        \"\"\"Load all DICOM files from a directory and sort them by slice position\"\"\"\n",
    "        dicom_files = []\n",
    "        \n",
    "        # get all .dcm files in the directory\n",
    "        for filename in os.listdir(directory_path):\n",
    "            if filename.endswith('.dcm'):\n",
    "                filepath = os.path.join(directory_path, filename)\n",
    "                try:\n",
    "                    dicom = pydicom.dcmread(filepath, force=True)\n",
    "                    dicom_files.append(dicom)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {filepath}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Sort slices by instance number or z-position\n",
    "        if dicom_files:\n",
    "            try:\n",
    "                print(\"success from 1\")\n",
    "                dicom_files.sort(key=lambda x: int(x.InstanceNumber))\n",
    "            except:\n",
    "                try:\n",
    "                    print(\"success from 1\")\n",
    "                    dicom_files.sort(key=lambda x: float(x.ImagePositionPatient[2]))\n",
    "                except:   \n",
    "                    print(\"success from 1\") \n",
    "                    dicom_files.sort(key=lambda x: x.filename)\n",
    "            \n",
    "            # Extract pixel data and stack into 3D volume\n",
    "            slices = []\n",
    "            \n",
    "            for dicom in dicom_files:\n",
    "                # Get pixel array\n",
    "                pixel_array = dicom.pixel_array\n",
    "                \n",
    "                # Apply rescale slope and intercept if available\n",
    "                if hasattr(dicom, 'RescaleSlope') and hasattr(dicom, 'RescaleIntercept'):\n",
    "                    pixel_array = pixel_array * dicom.RescaleSlope + dicom.RescaleIntercept\n",
    "                \n",
    "                slices.append(pixel_array)\n",
    "            \n",
    "            # Stack slices to create 3D volume\n",
    "            volume = np.stack(slices, axis=0)  # Shape: (depth, height, width)\n",
    "            return volume\n",
    "        else:\n",
    "            raise ValueError(f\"No DICOM files found in {directory_path}\")\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        row = self.dataframe.iloc[idx]\n",
    "        dicom_dir = row['ct_folder_path']\n",
    "        original_label = row['stage']\n",
    "        \n",
    "        if original_label == 2:\n",
    "            label = 0\n",
    "        elif original_label == 4:\n",
    "            label = 1\n",
    "        \n",
    "        # Load the DICOM series as 3D volume\n",
    "        volume = self._load_dicom_series(dicom_dir)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            volume = self.transform(volume)\n",
    "        \n",
    "        return volume, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "csv_file_path = \"colorectal_ct_patients.csv\"\n",
    "dataset = CTDataset(csv_file=csv_file_path)\n",
    "\n",
    "visualize = False\n",
    "\n",
    "if visualize:\n",
    "    for i in range(1, 350):\n",
    "        volume, label = dataset[i]\n",
    "        print(f\"Patient {i}: Volume shape {volume.shape}, Label: {label}\")\n",
    "\n",
    "    \n",
    "# # Define transforms for the 3D volume\n",
    "# transforms = Compose([\n",
    "#     EnsureChannelFirst(channel_dim='no_channel'),  # Adds channel dimension: (C, D, H, W)\n",
    "#     ScaleIntensity(minv=0.0, maxv=1.0),\n",
    "#     Resize(spatial_size=(64, 224, 224))  # Resize to consistent spatial size\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fc56d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display images and show information\n",
    "\n",
    "def plot_ct_slices_with_windowing(volume, num_rows=4, num_cols=10, window_center = 40, window_width = 400):\n",
    "    \n",
    "    \"\"\"\n",
    "    Keras-style plotting with CT windowing applied\n",
    "    \"\"\"\n",
    "\n",
    "    def apply_ct_window(image, window_center, window_width):\n",
    "\n",
    "        window_min = window_center - window_width // 2\n",
    "        window_max = window_center + window_width // 2\n",
    "        windowed = np.clip(image, window_min, window_max)\n",
    "        normalized = (windowed - window_min) / (window_max - window_min)\n",
    "        return normalized\n",
    "    \n",
    "    # Handle different input shapes\n",
    "    if len(volume.shape) == 4:\n",
    "        \n",
    "        volume = volume.squeeze(0)\n",
    "    \n",
    "    depth, _, _ = volume.shape\n",
    "    \n",
    "    total_slices = num_rows * num_cols\n",
    "    start_slice = max(0, depth // 2 - total_slices // 2)\n",
    "    end_slice = min(depth, start_slice + total_slices)\n",
    "    \n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(num_rows):\n",
    "\n",
    "        for j in range(num_cols):\n",
    "\n",
    "            slice_idx = start_slice + i * num_cols + j\n",
    "            \n",
    "            if slice_idx < end_slice:\n",
    "\n",
    "                slice_data = volume[slice_idx]\n",
    "                windowed_slice = apply_ct_window(slice_data, window_center, window_width)\n",
    "                \n",
    "                axes[i, j].imshow(windowed_slice, cmap='gray')\n",
    "                axes[i, j].set_title(f'S{slice_idx}', fontsize=8, pad=2)\n",
    "                axes[i, j].axis('off')\n",
    "                \n",
    "            else:\n",
    "\n",
    "                axes[i, j].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'CT Slices with Window [C:{window_center}, W:{window_width}]', y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def quick_view(dataset, patient_idx, rows=4, cols=8):\n",
    "\n",
    "    \"\"\"One-liner to view any patient\"\"\"\n",
    "    volume, label = dataset[patient_idx]\n",
    "    \n",
    "    if hasattr(volume, 'numpy'):\n",
    "        volume = volume.numpy()\n",
    "    \n",
    "    if len(volume.shape) == 4:\n",
    "        volume = volume.squeeze(0)\n",
    "    \n",
    "    print(f\"Patient {patient_idx}, Label: {label}, Shape: {volume.shape}\")\n",
    "    plot_ct_slices_with_windowing(volume, num_rows=rows, num_cols=cols)\n",
    "\n",
    "\n",
    "def check_slice_details(dataset, patient_idx):\n",
    "    volume, _ = dataset[patient_idx]\n",
    "    \n",
    "    if hasattr(volume, 'numpy'):\n",
    "        volume = volume.numpy()\n",
    "    if len(volume.shape) == 4:\n",
    "        volume = volume.squeeze(0)\n",
    "    \n",
    "    depth, height, width = volume.shape\n",
    "    print(f\"Patient {patient_idx}:\")\n",
    "    print(f\" - Total slices: {depth}\")\n",
    "    print(f\" - Slice resolution: {height} Ã— {width} pixels\")\n",
    "    print(f\" - HU value range: [{volume.min():.0f}, {volume.max():.0f}]\")\n",
    "    \n",
    "\n",
    "show_info = False\n",
    "\n",
    "if show_info:\n",
    "    check_slice_details(dataset, 111)\n",
    "    quick_view(dataset, 111)\n",
    "    check_slice_details(dataset, 400)\n",
    "    quick_view(dataset, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce34e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(width = 224, height = 224, depth = 64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((depth, height, width, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width = 224, height = 224, depth = 64)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",  # Use sparse since labels are 0,1\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"best_3d_ct_model.keras\", \n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy'\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", \n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f754eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PyTorch DataLoader to Keras-compatible format\n",
    "def pytorch_to_keras_generator(pytorch_loader):\n",
    "    \"\"\"Convert PyTorch DataLoader to Keras generator\"\"\"\n",
    "    while True:\n",
    "        for images, labels in pytorch_loader:\n",
    "            # Convert PyTorch tensors to numpy arrays\n",
    "            images_np = images.numpy()\n",
    "            labels_np = labels.numpy()\n",
    "            \n",
    "            # Keras expects channels_last: (batch, depth, height, width, channels)\n",
    "            images_np = np.transpose(images_np, (0, 2, 3, 4, 1))\n",
    "            \n",
    "            yield images_np, labels_np\n",
    "\n",
    "# Create Keras-compatible generators\n",
    "train_gen = pytorch_to_keras_generator(train_loader)\n",
    "val_gen = pytorch_to_keras_generator(val_loader)\n",
    "\n",
    "# Calculate steps per epoch\n",
    "train_steps = len(train_loader)\n",
    "val_steps = len(val_loader)\n",
    "\n",
    "# Now train with generators\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e910057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
